from airflow import DAG
from airflow.utils.dates import days_ago
from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import KubernetesPodOperator
from airflow.operators.python import PythonOperator
from airflow.kubernetes.pod_generator import PodGenerator
from kubernetes.client import models as k8s
from kubernetes import client, config
import logging

EXPERIMENT_NAME = "{{ config.run_config.experiment_name | slugify }}"

args = {
    'owner': 'airflow',
}

{% if mlflow_url %}
{{ include_start_mlflow_experiment_operator | safe }}
{% endif %}
{% if not config.run_config.volume.disabled %}
{{ include_create_pipeline_storage_operator | safe }}
{{ include_delete_pipeline_storage_operator | safe }}
{% endif %}

with DAG(
    dag_id='{{ dag_name }}',
    description='{{ config.run_config.description }}',
    default_args=args,
    schedule_interval={% if schedule_interval %}'{{ schedule_interval }}'{% else %}None{% endif %},
    start_date=days_ago(2),
    tags=['commit_sha:{{ git_info.commit_sha }}',
            'generated_with_kedro_airflow_k8s:{{ kedro_airflow_k8s_version }}',
            'experiment_name:'+EXPERIMENT_NAME],
    params={},
) as dag:

    pvc_name = '{{ project_name | safe | slugify }}.{% raw %}{{ ts_nodash | lower  }}{% endraw %}'

    {% if mlflow_url %}
    start_mlflow_run = StartMLflowExperimentOperator(
        experiment_name=EXPERIMENT_NAME,
        mlflow_url='{{ mlflow_url }}'
    )
    {% endif %}

    {% if not config.run_config.volume.disabled %}
    create_pipeline_storage = CreatePipelineStorageOperator(
        pvc_name=pvc_name,
        namespace='{{ config.run_config.namespace }}',
        access_modes={{config.run_config.volume.access_modes | safe}},
        volume_size='{{ config.run_config.volume.size }}',
        storage_class_name='{{ config.run_config.volume.storageclass }}'
    )

    delete_pipeline_storage = DeletePipelineStorageOperator(
        pvc_name=pvc_name,
        namespace='{{ config.run_config.namespace }}'
    )

       {% if not config.run_config.volume.skip_init %}
    data_volume_init_definition = """
    apiVersion: v1
    kind: Pod
    metadata:
      name: """ + PodGenerator.make_unique_pod_id('data-volume-init') + """
      namespace: {{ config.run_config.namespace }}
    spec:
      securityContext:
        fsGroup: {{ config.run_config.volume.owner }}
      volumes:
        - name: storage
          persistentVolumeClaim:
            claimName: """ + pvc_name + """
      containers:
        - name: base
          image: {{ image }}
          imagePullPolicy: {{ config.run_config.image_pull_policy }}
          command:
            - "bash"
            - "-c"
          args:
            - cp --verbose -r /home/kedro/data/* /home/kedro/datavolume
          volumeMounts:
            - mountPath: "/home/kedro/datavolume"
              name: storage
    """

    data_volume_init = KubernetesPodOperator(
        task_id="data_volume_init",
        is_delete_operator_pod=True,
        startup_timeout_seconds={{ config.run_config.startup_timeout }},
        pod_template_file=data_volume_init_definition
    )
        {% endif %}
    {% endif %}
    tasks = {}
    {% for node in pipeline.nodes %}
    pod_definition = """
        apiVersion: v1
        kind: Pod
        metadata:
          name: """ + PodGenerator.make_unique_pod_id('{{ node.name | slugify }}') + """
          namespace: {{ config.run_config.namespace }}
        spec:
          securityContext:
            fsGroup: {{ config.run_config.volume.owner }}
          {%- if not config.run_config.volume.disabled %}
          volumes:
            - name: storage
              persistentVolumeClaim:
                claimName: """ + pvc_name + """
          {%- endif %}
          containers:
            - name: base
              image: {{ image }}
              imagePullPolicy: {{ config.run_config.image_pull_policy }}{% if mlflow_url %}
              env:
                - name: MLFLOW_RUN_ID
                  value: {% raw %}{{ task_instance.xcom_pull(key="mlflow_run_id") }}{% endraw %}{% endif %}
              args:
                - 'kedro'
                - 'run'
                - '-e' 
                - '{{ env }}'
                - '--node'
                - '{{ node.name }}'
              {%- if not config.run_config.volume.disabled %}
              volumeMounts:
                - mountPath: "/home/kedro/data"
                  name: storage
              {%- endif %}
              resources:
                requests:
                {%- if resources[node.name].requests.cpu %}
                  cpu: "{{ resources[node.name].requests.cpu }}"
                {%- endif %}
                {%- if resources[node.name].requests.memory %}
                  memory: "{{ resources[node.name].requests.memory }}"
                {%- endif %}
                limits:
                {%- if resources[node.name].limits.cpu %}
                  cpu: "{{ resources[node.name].limits.cpu }}"
                {%- endif %}
                {%- if resources[node.name].limits.memory %}
                  memory: "{{ resources[node.name].limits.memory }}"
                {%- endif %}
          {%- if resources[node.name].labels %}
          nodeSelector:
            {%- for key, value in resources[node.name].labels.items() %}
            {{ key }}: {{ value }}
            {%- endfor %}
          {% endif %}

    """

    tasks["{{ node.name | slugify }}"] = KubernetesPodOperator(
        task_id="{{ node.name | slugify }}",
        is_delete_operator_pod=True,
        startup_timeout_seconds={{ config.run_config.startup_timeout }},
        pod_template_file=pod_definition
    )
    {% endfor %}

    
    {% for parent_node, child_nodes in dependencies.items() -%}
    {% for child in child_nodes %}
    tasks["{{ parent_node.name | slugify }}"] >> tasks["{{ child.name | slugify }}"]
    {% endfor %}
    {%- endfor %}

    {% if not config.run_config.volume.disabled %}
        {% if not config.run_config.volume.skip_init %}
    create_pipeline_storage >> data_volume_init
    data_volume_init >> delete_pipeline_storage
        {% else %}
    create_pipeline_storage >> delete_pipeline_storage
        {% endif %}
    {% endif %}

    {% for node in base_nodes %}
    {% if mlflow_url %}
    start_mlflow_run >> tasks['{{ node | slugify }}']
    {% endif %}
    {% if not config.run_config.volume.disabled and not config.run_config.volume.skip_init %}
    data_volume_init >> tasks['{{ node | slugify }}']
    {% endif %}
    {% endfor %}

    {% if not config.run_config.volume.disabled %}
    {% for node in bottom_nodes %}
    tasks['{{ node | slugify }}'] >> delete_pipeline_storage
    {% endfor %}
    {% endif %}

if __name__ == "__main__":
    dag.cli()
